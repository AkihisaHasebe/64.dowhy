"""Page 2: åˆ†æå®Ÿè¡Œ â€” æ‰‹æ³•é¸æŠ â†’ ä¸€æ‹¬å®Ÿè¡Œ â†’ çµæœè¡¨ç¤º"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import networkx as nx
import matplotlib
import matplotlib.pyplot as plt
import time
from datetime import datetime, timedelta
matplotlib.rcParams['font.family'] = 'Meiryo'

st.header("åˆ†æå®Ÿè¡Œ")

if "df" not in st.session_state:
    st.warning("ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
    st.stop()

df = st.session_state["df"]
target = st.session_state["target"]
features = st.session_state["features"]
gt = st.session_state.get("ground_truth")


# ============================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================

def _cat(f):
    if not gt:
        return "ä¸æ˜"
    if f in gt["direct_causes"]:
        return "ç›´æ¥åŸå› "
    if f in gt["spurious"]:
        return "æ“¬ä¼¼ç›¸é–¢"
    if f in gt["independent"]:
        return "ç‹¬ç«‹ãƒã‚¤ã‚º"
    if f in gt["upstream"]:
        return "ä¸Šæµå¤‰æ•°"
    return "ä¸æ˜"


def _color(f):
    cat = _cat(f)
    return {
        "ç›´æ¥åŸå› ": "#2196F3", "æ“¬ä¼¼ç›¸é–¢": "#F44336",
        "ç‹¬ç«‹ãƒã‚¤ã‚º": "#9E9E9E", "ä¸Šæµå¤‰æ•°": "#FF9800",
    }.get(cat, "#607D8B")


# ============================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: æ‰‹æ³•é¸æŠ + ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# ============================================================

st.sidebar.subheader("å®Ÿè¡Œã™ã‚‹æ‰‹æ³•")
run_lingam = st.sidebar.checkbox("LiNGAM", value=True, key="sel_lingam")
run_pc = st.sidebar.checkbox("PC", value=True, key="sel_pc")
run_fci = st.sidebar.checkbox("FCI", value=True, key="sel_gfci")
run_grasp = st.sidebar.checkbox("GRaSP", value=True, key="sel_grasp")

# --- LiNGAM ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---
if run_lingam:
    st.sidebar.subheader("LiNGAM ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    lingam_bootstrap = st.sidebar.slider("Bootstrap å›æ•°", 10, 200, 100, 10,
                                          key="lingam_bs")
    lingam_min_effect = st.sidebar.number_input("min_causal_effect", 0.001, 0.1,
                                                 0.01, 0.005, key="lingam_me")
    lingam_threshold = st.sidebar.slider("ã‚¨ãƒƒã‚¸æ¡ç”¨ç¢ºç‡é–¾å€¤", 0.1, 0.9, 0.50, 0.05,
                                          key="lingam_th")

# --- PC / FCI å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---
if run_pc or run_fci:
    st.sidebar.subheader("PC / FCI ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    pcfci_alpha = st.sidebar.slider("æœ‰æ„æ°´æº– (alpha)", 0.01, 0.2, 0.05, 0.01,
                                     key="pcfci_a")
    pcfci_indep = st.sidebar.selectbox("ç‹¬ç«‹æ€§æ¤œå®š",
                                        ["fisherz", "chisq", "gsq", "kci"],
                                        key="pcfci_ind")

if run_pc:
    pc_bootstrap = st.sidebar.slider("Bootstrap å›æ•° (PC)", 10, 200, 100, 10,
                                      key="pc_bs")
    pc_threshold = st.sidebar.slider("ã‚¨ãƒƒã‚¸æ¡ç”¨ç¢ºç‡é–¾å€¤ (PC)", 0.1, 0.9, 0.50, 0.05,
                                      key="pc_th")

# --- GRaSP ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---
if run_grasp:
    st.sidebar.subheader("GRaSP ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    grasp_score_func = st.sidebar.selectbox(
        "ã‚¹ã‚³ã‚¢é–¢æ•°", ["local_score_BIC", "local_score_BDeu"],
        key="grasp_score")
    grasp_depth = st.sidebar.slider("æ¢ç´¢æ·±åº¦ (depth)", 1, 5, 3, 1,
                                     key="grasp_depth")
    grasp_bootstrap = st.sidebar.slider("Bootstrap å›æ•° (GRaSP)", 10, 200, 100, 10,
                                         key="grasp_bs")
    grasp_threshold = st.sidebar.slider("ã‚¨ãƒƒã‚¸æ¡ç”¨ç¢ºç‡é–¾å€¤ (GRaSP)", 0.1, 0.9, 0.50, 0.05,
                                         key="grasp_th")

# ============================================================
# å®Ÿè¡Œãƒœã‚¿ãƒ³
# ============================================================

if not any([run_lingam, run_pc, run_fci, run_grasp]):
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å®Ÿè¡Œã™ã‚‹æ‰‹æ³•ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ============================================================
# å®Ÿè¡Œæ™‚é–“æ¨å®šé–¢æ•°
# ============================================================

def estimate_execution_time(df, methods_config):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿè¡Œæ™‚é–“ã‚’æ¨å®šã™ã‚‹

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        methods_config: dict with method names and their parameters

    Returns:
        dict: {method: estimated_seconds, "total": total_seconds}
    """
    n_samples = len(df)
    n_features = len(df.columns)

    estimates = {}

    # çµŒé¨“çš„ä¿‚æ•° (2000ã‚µãƒ³ãƒ—ãƒ«, 20å¤‰æ•°ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹)
    # å®Ÿéš›ã®ç’°å¢ƒã‚„ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã«ã‚ˆã‚Šå¤‰å‹•ã™ã‚‹ãŸã‚ã€ã‚ãã¾ã§ç›®å®‰

    for method, params in methods_config.items():
        if method == "LiNGAM":
            # O(nÂ³) + Bootstrap
            # åŸºæº–: 2000ã‚µãƒ³ãƒ—ãƒ«, 100 bootstrap ã§ç´„10-20ç§’
            base_time = 0.15 * (n_samples / 2000) ** 2  # ICAè¨ˆç®—
            bootstrap_time = params.get("bootstrap", 100) * 0.12
            estimates["LiNGAM"] = base_time + bootstrap_time

        elif method == "PC":
            # O(n Ã— pÂ²) + Bootstrap
            # åŸºæº–: 2000ã‚µãƒ³ãƒ—ãƒ«, 20å¤‰æ•°, 100 bootstrap ã§ç´„30-50ç§’
            base_time = 0.3 * (n_samples / 2000) * (n_features / 20) ** 2
            bootstrap_time = params.get("bootstrap", 100) * 0.35
            estimates["PC"] = base_time + bootstrap_time

        elif method == "FCI":
            # O(n Ã— pÂ²) with greedy optimization, bootstrapãªã—
            # åŸºæº–: 2000ã‚µãƒ³ãƒ—ãƒ«, 20å¤‰æ•°ã§ç´„2-4ç§’ (æ¡ä»¶ä»˜ãç‹¬ç«‹æ€§æ¤œå®šãƒ™ãƒ¼ã‚¹)
            estimates["FCI"] = 3.0 * (n_samples / 2000) * (n_features / 20) ** 2

        elif method == "GRaSP":
            # O(pÂ³ Ã— depth) + Bootstrap
            # åŸºæº–: 20å¤‰æ•°, depth=3, 100 bootstrap ã§ç´„25-40ç§’
            depth = params.get("depth", 3)
            base_time = 0.6 * (n_features / 20) ** 3 * (depth / 3)
            bootstrap_time = params.get("bootstrap", 100) * 0.3
            estimates["GRaSP"] = base_time + bootstrap_time

    estimates["total"] = sum(estimates.values())
    return estimates

# ============================================================
# å®Ÿè¡Œæ™‚é–“æ¨å®šã®è¡¨ç¤º
# ============================================================

if any([run_lingam, run_pc, run_fci, run_grasp]):
    # é¸æŠã•ã‚ŒãŸæ‰‹æ³•ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã‚‹
    methods_config = {}
    if run_lingam:
        methods_config["LiNGAM"] = {"bootstrap": lingam_bootstrap}
    if run_pc:
        methods_config["PC"] = {"bootstrap": pc_bootstrap}
    if run_fci:
        methods_config["FCI"] = {}
    if run_grasp:
        methods_config["GRaSP"] = {"bootstrap": grasp_bootstrap, "depth": grasp_depth}

    # æ¨å®šæ™‚é–“ã‚’è¨ˆç®—
    time_estimates = estimate_execution_time(df, methods_config)
    total_estimate = time_estimates["total"]

    # æ¨å®šæ™‚é–“ã‚’è¡¨ç¤º
    if total_estimate < 60:
        time_str = f"ç´„ {total_estimate:.0f} ç§’"
    else:
        minutes = int(total_estimate // 60)
        seconds = int(total_estimate % 60)
        time_str = f"ç´„ {minutes} åˆ† {seconds} ç§’"

    # è­¦å‘Šãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè¡¨ç¤º
    if total_estimate > 180:  # 3åˆ†ä»¥ä¸Š
        st.warning(f"âš ï¸ æ¨å®šå®Ÿè¡Œæ™‚é–“: {time_str} (ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚„ bootstrap å›æ•°ãŒå¤§ãã„ãŸã‚æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)")
    elif total_estimate > 60:  # 1åˆ†ä»¥ä¸Š
        st.info(f"â±ï¸ æ¨å®šå®Ÿè¡Œæ™‚é–“: {time_str}")
    else:
        st.caption(f"â±ï¸ æ¨å®šå®Ÿè¡Œæ™‚é–“: {time_str}")

    # è©³ç´°ã‚’ expander ã§è¡¨ç¤º
    with st.expander("ğŸ“Š æ‰‹æ³•åˆ¥ã®æ¨å®šå®Ÿè¡Œæ™‚é–“", expanded=False):
        est_df = pd.DataFrame([
            {"æ‰‹æ³•": method, "æ¨å®šæ™‚é–“ (ç§’)": f"{est:.1f}",
             "å‰²åˆ (%)": f"{est/total_estimate*100:.0f}"}
            for method, est in time_estimates.items() if method != "total"
        ])
        st.dataframe(est_df, use_container_width=True, hide_index=True)
        st.caption(
            "â€» æ¨å®šæ™‚é–“ã¯ç›®å®‰ã§ã™ã€‚å®Ÿéš›ã®å®Ÿè¡Œæ™‚é–“ã¯ CPU æ€§èƒ½ã€ãƒ¡ãƒ¢ãƒªã€ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã«ã‚ˆã‚Šå¤‰å‹•ã—ã¾ã™ã€‚"
        )

if st.button("åˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
    methods = []
    if run_lingam:
        methods.append("LiNGAM")
    if run_pc:
        methods.append("PC")
    if run_fci:
        methods.append("FCI")
    if run_grasp:
        methods.append("GRaSP")

    # é€²æ—è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    progress_container = st.container()
    with progress_container:
        progress = st.progress(0, text="æº–å‚™ä¸­...")
        status_text = st.empty()

    total = len(methods)
    timing_results = {}
    overall_start = time.time()

    for i, method in enumerate(methods):
        method_start = time.time()
        start_time_str = datetime.now().strftime("%H:%M:%S")

        # é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        progress.progress(i / total, text=f"{method} å®Ÿè¡Œä¸­...")
        status_text.markdown(f"**{method}** ã‚’å®Ÿè¡Œä¸­... (é–‹å§‹: {start_time_str})")

        if method == "LiNGAM":
            from analysis.lingam_analysis import run_lingam as _run_lingam
            status_text.markdown(
                f"**LiNGAM** ã‚’å®Ÿè¡Œä¸­...\n"
                f"- DirectLiNGAM ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§å› æœé †åºã‚’æ¨å®šä¸­\n"
                f"- Bootstrap ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {lingam_bootstrap} å›\n"
                f"- é–‹å§‹: {start_time_str}"
            )
            result = _run_lingam(df, target, lingam_bootstrap, lingam_min_effect,
                                 lingam_threshold)
            st.session_state["lingam_result"] = result
            elapsed = time.time() - method_start
            timing_results["LiNGAM"] = elapsed
            progress.progress((i + 0.5) / total,
                            text=f"{method} å®Œäº† ({elapsed:.1f}ç§’)")
            status_text.markdown(
                f"âœ… **LiNGAM** å®Œäº† ({elapsed:.1f} ç§’) â€” "
                f"å› æœé †åº: {len(result['causal_order'])} å¤‰æ•°"
            )

        elif method == "PC":
            from analysis.pc_fci_analysis import run_pc as _run_pc
            data = df.values
            column_names = list(df.columns)
            status_text.markdown(
                f"**PC** ã‚’å®Ÿè¡Œä¸­...\n"
                f"- æ¡ä»¶ä»˜ãç‹¬ç«‹æ€§æ¤œå®š ({pcfci_indep}) ã§ CPDAG ã‚’æ§‹ç¯‰ä¸­\n"
                f"- Bootstrap ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {pc_bootstrap} å›\n"
                f"- æœ‰æ„æ°´æº–: {pcfci_alpha}\n"
                f"- é–‹å§‹: {start_time_str}"
            )
            result = _run_pc(data, column_names, target, pcfci_alpha, pcfci_indep,
                             pc_bootstrap, pc_threshold)
            st.session_state["pc_result"] = result
            elapsed = time.time() - method_start
            timing_results["PC"] = elapsed
            progress.progress((i + 0.5) / total,
                            text=f"{method} å®Œäº† ({elapsed:.1f}ç§’)")
            status_text.markdown(
                f"âœ… **PC** å®Œäº† ({elapsed:.1f} ç§’) â€” "
                f"æ¤œå‡ºã‚¨ãƒƒã‚¸: {len(result['edges_df'])} æœ¬"
            )

        elif method == "FCI":
            from analysis.pc_fci_analysis import run_fci as _run_fci
            data = df.values
            column_names = list(df.columns)
            status_text.markdown(
                f"**FCI** ã‚’å®Ÿè¡Œä¸­...\n"
                f"- æ½œåœ¨äº¤çµ¡å› å­ã‚’è€ƒæ…®ã—ãŸ PAG ã‚’æ§‹ç¯‰ä¸­\n"
                f"- ç‹¬ç«‹æ€§æ¤œå®š: {pcfci_indep}\n"
                f"- æœ‰æ„æ°´æº–: {pcfci_alpha}\n"
                f"- é–‹å§‹: {start_time_str}"
            )
            result = _run_fci(data, column_names, target, pcfci_alpha, pcfci_indep)
            st.session_state["fci_result"] = result
            elapsed = time.time() - method_start
            timing_results["FCI"] = elapsed
            progress.progress((i + 0.5) / total,
                            text=f"{method} å®Œäº† ({elapsed:.1f}ç§’)")
            status_text.markdown(
                f"âœ… **FCI** å®Œäº† ({elapsed:.1f} ç§’) â€” "
                f"æ¤œå‡ºã‚¨ãƒƒã‚¸: {len(result['edges_df'])} æœ¬"
            )

        elif method == "GRaSP":
            from analysis.grasp_analysis import run_grasp as _run_grasp
            data = df.values
            column_names = list(df.columns)
            status_text.markdown(
                f"**GRaSP** ã‚’å®Ÿè¡Œä¸­...\n"
                f"- é †åˆ—ãƒ™ãƒ¼ã‚¹ã®å› æœæ¢ç´¢ (depth={grasp_depth})\n"
                f"- Bootstrap ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {grasp_bootstrap} å›\n"
                f"- ã‚¹ã‚³ã‚¢é–¢æ•°: {grasp_score_func}\n"
                f"- é–‹å§‹: {start_time_str}"
            )
            result = _run_grasp(data, column_names, target, grasp_score_func,
                                depth=grasp_depth, n_bootstrap=grasp_bootstrap,
                                threshold=grasp_threshold)
            st.session_state["grasp_result"] = result
            elapsed = time.time() - method_start
            timing_results["GRaSP"] = elapsed
            progress.progress((i + 0.5) / total,
                            text=f"{method} å®Œäº† ({elapsed:.1f}ç§’)")
            status_text.markdown(
                f"âœ… **GRaSP** å®Œäº† ({elapsed:.1f} ç§’) â€” "
                f"æ¤œå‡ºã‚¨ãƒƒã‚¸: {len(result['edges_df'])} æœ¬"
            )

    overall_elapsed = time.time() - overall_start

    # --- çµ±åˆã‚°ãƒ©ãƒ•æ§‹ç¯‰ + DoWhy å› æœåŠ¹æœæ¨å®š ---
    consensus_start = time.time()
    consensus_start_str = datetime.now().strftime("%H:%M:%S")
    progress.progress(0.95, text="çµ±åˆå› æœã‚°ãƒ©ãƒ•æ§‹ç¯‰ + DoWhy å› æœåŠ¹æœæ¨å®šä¸­...")
    status_text.markdown(
        f"**çµ±åˆå› æœã‚°ãƒ©ãƒ•æ§‹ç¯‰** ã‚’å®Ÿè¡Œä¸­...\n"
        f"- è¤‡æ•°æ‰‹æ³•ã®çµæœã‚’çµ±åˆã—ã¦ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰\n"
        f"- DoWhy ã«ã‚ˆã‚‹å› æœåŠ¹æœæ¨å®š (Backdoor criterion)\n"
        f"- é–‹å§‹: {consensus_start_str}"
    )
    try:
        from analysis.consensus_graph import build_consensus_graph, get_adjacent_to_target
        from analysis.dowhy_estimation import estimate_causal_effects_with_dowhy

        # çµ±åˆã‚°ãƒ©ãƒ•æ§‹ç¯‰
        consensus_graph, edge_support_df = build_consensus_graph(
            st.session_state, target, features, min_agreement=2
        )
        st.session_state["consensus_graph"] = consensus_graph
        st.session_state["edge_support_df"] = edge_support_df
        st.session_state["consensus_adjacent"] = get_adjacent_to_target(
            consensus_graph, target
        )

        # DoWhy å› æœåŠ¹æœæ¨å®š
        dowhy_results = estimate_causal_effects_with_dowhy(
            df, target, features, consensus_graph
        )
        st.session_state["dowhy_results"] = dowhy_results

        consensus_elapsed = time.time() - consensus_start
        status_text.markdown(
            f"âœ… **çµ±åˆå‡¦ç†** å®Œäº† ({consensus_elapsed:.1f} ç§’) â€” "
            f"çµ±åˆã‚¨ãƒƒã‚¸: {len(edge_support_df)} æœ¬"
        )

    except Exception as e:
        st.session_state["consensus_graph"] = None
        st.session_state["dowhy_results"] = {}
        st.warning(f"çµ±åˆã‚°ãƒ©ãƒ• or DoWhy æ¨å®šã§ã‚¨ãƒ©ãƒ¼: {e}")

    overall_elapsed = time.time() - overall_start
    end_time_str = datetime.now().strftime("%H:%M:%S")
    progress.progress(1.0, text=f"å®Œäº† (åˆè¨ˆ: {overall_elapsed:.1f}ç§’)")
    status_text.markdown(
        f"ğŸ‰ **å…¨ã¦ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼**\n\n"
        f"- å®Ÿè¡Œæ‰‹æ³•: {', '.join(methods)}\n"
        f"- ç·å®Ÿè¡Œæ™‚é–“: {overall_elapsed:.1f} ç§’\n"
        f"- çµ‚äº†: {end_time_str}"
    )

    # æ™‚é–“è¨ˆæ¸¬çµæœã‚’ä¿å­˜
    st.session_state["timing_results"] = timing_results
    st.session_state["overall_time"] = overall_elapsed

    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«æ™‚é–“ã‚’å«ã‚ã‚‹
    st.success(f"{', '.join(methods)} ã®å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆåˆè¨ˆ {overall_elapsed:.1f} ç§’ï¼‰")

    # å®Ÿè¡Œæ™‚é–“ã‚µãƒãƒªãƒ¼
    with st.expander("â±ï¸ å®Ÿè¡Œæ™‚é–“ã®è©³ç´°", expanded=False):
        timing_df = pd.DataFrame([
            {"æ‰‹æ³•": method, "å®Ÿè¡Œæ™‚é–“ (ç§’)": f"{elapsed:.2f}",
             "å‰²åˆ (%)": f"{elapsed/overall_elapsed*100:.1f}"}
            for method, elapsed in timing_results.items()
        ])
        st.dataframe(timing_df, use_container_width=True, hide_index=True)

        # è¨ˆç®—é‡ã®å‚è€ƒæƒ…å ±
        st.caption(
            f"**è¨ˆç®—é‡ã®ç›®å®‰** (ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}, å¤‰æ•°æ•°: {len(df.columns)})\n"
            f"- LiNGAM: O(nÂ³) - ICAåå¾© + Bootstrap\n"
            f"- PC/FCI: O(n Ã— pÂ²) - æ¡ä»¶ä»˜ãç‹¬ç«‹æ€§æ¤œå®š\n"
            f"- GRaSP: O(pÂ³ Ã— depth) - é †åˆ—æ¢ç´¢ + Bootstrap\n"
            f"â€» n=ã‚µãƒ³ãƒ—ãƒ«æ•°, p=å¤‰æ•°æ•°"
        )

# ============================================================
# çµæœãŒãªã‘ã‚Œã°åœæ­¢
# ============================================================

has_lingam = "lingam_result" in st.session_state
has_pc = "pc_result" in st.session_state
has_fci = "fci_result" in st.session_state
has_grasp = "grasp_result" in st.session_state

if not any([has_lingam, has_pc, has_fci, has_grasp]):
    st.info("ã€Œåˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ============================================================
# ä»‹å…¥å„ªå…ˆåº¦ã‚µãƒãƒªãƒ¼ (çµæœã®å†’é ­ã«è¡¨ç¤º)
# ============================================================

st.markdown("---")
st.subheader(f"{target} ã¸ã®ä»‹å…¥å„ªå…ˆåº¦ã‚µãƒãƒªãƒ¼")

# å®Ÿè¡Œæ™‚é–“æƒ…å ±ã®è¡¨ç¤ºï¼ˆæ—¢å­˜çµæœã®å ´åˆã‚‚è¡¨ç¤ºï¼‰
if "timing_results" in st.session_state and st.session_state["timing_results"]:
    timing_info = st.session_state["timing_results"]
    overall_time = st.session_state.get("overall_time", sum(timing_info.values()))
    executed_methods = list(timing_info.keys())

    st.info(
        f"âœ“ å®Ÿè¡Œæ¸ˆã¿æ‰‹æ³•: {', '.join(executed_methods)} "
        f"ï¼ˆåˆè¨ˆ: {overall_time:.1f} ç§’ï¼‰"
    )

# ============================================================
# åŠ¹æœé‡ã®æ¨å®š (OLS æ¨™æº–åŒ–å›å¸°ä¿‚æ•° â€” å…¨æ‰‹æ³•ã§åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)
# ============================================================
from sklearn.linear_model import LinearRegression

_X_all = df[features].values
_y_all = df[target].values
_lr = LinearRegression().fit(_X_all, _y_all)
_sds = df[features].std().values
_sd_y = df[target].std()
# æ¨™æº–åŒ–å›å¸°ä¿‚æ•°: Î²_std = Î²_raw Ã— (SD_x / SD_y)
_ols_std_coefs = pd.Series(
    _lr.coef_ * _sds / _sd_y, index=features
)

# ============================================================
# å„å¤‰æ•°ã®çµ±åˆã‚¹ã‚³ã‚¢ã‚’ç®—å‡º
# ============================================================

# DoWhy çµæœã®å–å¾—
dowhy_results = st.session_state.get("dowhy_results", {})
has_dowhy = len(dowhy_results) > 0

summary_rows = []
for f in features:
    row = {"å¤‰æ•°": f}

    # --- åŠ¹æœé‡ (æ¨™æº–åŒ–) ---
    # å„ªå…ˆé †ä½: DoWhy ATE > LiNGAM ç·ä»‹å…¥åŠ¹æœ > OLS å›å¸°ä¿‚æ•°
    if has_dowhy and f in dowhy_results and not np.isnan(dowhy_results[f].get("ate", np.nan)):
        # DoWhy ATE ã‚’æ¨™æº–åŒ– (SDå˜ä½ã«å¤‰æ›)
        ate = dowhy_results[f]["ate"]
        # ATE ã¯é€šå¸¸ã€Œ1å˜ä½å¢—åŠ ã«å¯¾ã™ã‚‹åŠ¹æœã€ãªã®ã§ã€æ¨™æº–åŒ–ã™ã‚‹ã«ã¯ SD ã§å‰²ã‚‹/æ›ã‘ã‚‹
        # ã“ã“ã§ã¯æ—¢ã«æ¨å®šå€¤ãŒå‡ºã¦ã„ã‚‹ã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨ (å¾Œã§æ¨™æº–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ å¯èƒ½)
        row["åŠ¹æœé‡(std)"] = ate
        row["ç›´æ¥åŠ¹æœ(std)"] = np.nan
        row["é–“æ¥åŠ¹æœ(std)"] = np.nan
        row["åŠ¹æœé‡ã‚½ãƒ¼ã‚¹"] = "DoWhy"
        row["DoWhyè­˜åˆ¥"] = dowhy_results[f].get("identified", False)
    elif has_lingam:
        res_l = st.session_state["lingam_result"]
        std_t = res_l["std_total_effects"]
        std_d = res_l["std_direct_effects"]
        row["åŠ¹æœé‡(std)"] = std_t.get(f, 0)
        row["ç›´æ¥åŠ¹æœ(std)"] = std_d.get(f, 0)
        row["é–“æ¥åŠ¹æœ(std)"] = std_t.get(f, 0) - std_d.get(f, 0)
        row["åŠ¹æœé‡ã‚½ãƒ¼ã‚¹"] = "LiNGAM"
        row["DoWhyè­˜åˆ¥"] = np.nan
    else:
        row["åŠ¹æœé‡(std)"] = _ols_std_coefs.get(f, 0)
        row["ç›´æ¥åŠ¹æœ(std)"] = np.nan
        row["é–“æ¥åŠ¹æœ(std)"] = np.nan
        row["åŠ¹æœé‡ã‚½ãƒ¼ã‚¹"] = "OLS"
        row["DoWhyè­˜åˆ¥"] = np.nan
    row["|åŠ¹æœé‡(std)|"] = abs(row["åŠ¹æœé‡(std)"])

    # --- å„æ‰‹æ³•ã®å› æœç¢ºä¿¡åº¦ (0-1) ---
    confidence_signals = []

    if has_lingam:
        prob = st.session_state["lingam_result"]["edge_probs_to_target"]
        row["LiNGAMç¢ºç‡"] = prob.get(f, 0)
        confidence_signals.append(prob.get(f, 0))
    else:
        row["LiNGAMç¢ºç‡"] = np.nan

    if has_pc:
        pc_probs = st.session_state["pc_result"]["bootstrap_probs"]
        # target è¡Œ (targetâ†f) ã¾ãŸã¯ target åˆ— (fâ†’target) ã®æœ€å¤§å€¤
        pc_prob_f = max(
            pc_probs.loc[target].get(f, 0) if f in pc_probs.columns else 0,
            pc_probs[target].get(f, 0) if f in pc_probs.index else 0,
        )
        row["PCç¢ºç‡"] = pc_prob_f
        row["PCéš£æ¥"] = 1 if f in st.session_state["pc_result"]["adjacent_to_target"] else 0
        confidence_signals.append(pc_prob_f)
    else:
        row["PCç¢ºç‡"] = np.nan
        row["PCéš£æ¥"] = np.nan

    if has_fci:
        fci_adj = 1.0 if f in st.session_state["fci_result"]["adjacent_to_target"] else 0.0
        row["FCIéš£æ¥"] = int(fci_adj)
        confidence_signals.append(fci_adj)
    else:
        row["FCIéš£æ¥"] = np.nan

    if has_grasp:
        grasp_probs = st.session_state["grasp_result"]["bootstrap_probs"]
        grasp_prob_f = max(
            grasp_probs.loc[target].get(f, 0) if f in grasp_probs.columns else 0,
            grasp_probs[target].get(f, 0) if f in grasp_probs.index else 0,
        )
        row["GRaSPç¢ºç‡"] = grasp_prob_f
        row["GRaSPéš£æ¥"] = 1 if f in st.session_state["grasp_result"]["adjacent_to_target"] else 0
        confidence_signals.append(grasp_prob_f)
    else:
        row["GRaSPç¢ºç‡"] = np.nan
        row["GRaSPéš£æ¥"] = np.nan

    # --- çµ±åˆå› æœç¢ºä¿¡åº¦ (å…¨æ‰‹æ³•ã®å¹³å‡) ---
    if confidence_signals:
        row["å› æœç¢ºä¿¡åº¦"] = np.mean(confidence_signals)
    else:
        row["å› æœç¢ºä¿¡åº¦"] = 0.0

    # --- çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢ = |åŠ¹æœé‡| Ã— å› æœç¢ºä¿¡åº¦ ---
    row["çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢"] = row["|åŠ¹æœé‡(std)|"] * row["å› æœç¢ºä¿¡åº¦"]

    # --- å› æœã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ•° (åˆ¤å®šç”¨) ---
    causal_evidence = 0
    if has_lingam and row["LiNGAMç¢ºç‡"] > 0.5:
        causal_evidence += 1
    if has_pc and row.get("PCéš£æ¥", 0) == 1:
        causal_evidence += 1
    if has_fci and row.get("FCIéš£æ¥", 0) == 1:
        causal_evidence += 1
    if has_grasp and row.get("GRaSPéš£æ¥", 0) == 1:
        causal_evidence += 1
    row["å› æœã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ•°"] = causal_evidence

    # --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
    n_causal_methods = sum([has_lingam, has_pc, has_fci, has_grasp])
    if n_causal_methods > 0 and causal_evidence >= 2:
        row["åˆ¤å®š"] = "ç›´æ¥åŸå›  (é«˜ç¢ºä¿¡)"
    elif n_causal_methods > 0 and causal_evidence == 1:
        row["åˆ¤å®š"] = "ç›´æ¥åŸå›  (ä½ç¢ºä¿¡)"
    else:
        row["åˆ¤å®š"] = "å½±éŸ¿ãªã—"

    if gt:
        row["çœŸã®ã‚«ãƒ†ã‚´ãƒª"] = _cat(f)

    summary_rows.append(row)

summary_df = pd.DataFrame(summary_rows).set_index("å¤‰æ•°")
summary_df = summary_df.sort_values("çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢", ascending=False)

# ============================================================
# çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢ ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
# ============================================================

st.markdown(f"**{target} ã¸ã®çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢**")
st.caption(
    "çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢ = |åŠ¹æœé‡ (æ¨™æº–åŒ–)| Ã— å› æœç¢ºä¿¡åº¦ã€‚"
    "åŠ¹æœé‡ã¯ **DoWhy ã«ã‚ˆã‚‹å› æœåŠ¹æœæ¨å®š (çµ±åˆã‚°ãƒ©ãƒ•ä½¿ç”¨)** > LiNGAM ã®ç·å› æœåŠ¹æœ > OLS å›å¸°ä¿‚æ•° ã®å„ªå…ˆé †ä½ã§é¸æŠã€‚"
    "å› æœç¢ºä¿¡åº¦ã¯ LiNGAM / PC / FCI / GRaSP ã®å¹³å‡ç¢ºç‡ (0ã€œ1)ã€‚"
    "ã€Œä»‹å…¥ã—ãŸæ™‚ã«ã©ã‚Œã ã‘ç›®çš„å¤‰æ•°ãŒå¤‰ã‚ã‚‹ã‹ã€ã¨"
    "ã€Œãã®å› æœé–¢ä¿‚ãŒã©ã‚Œã ã‘ä¿¡é ¼ã§ãã‚‹ã‹ã€ã®ä¸¡æ–¹ã‚’åæ˜ ã€‚"
)

fig_score = go.Figure()

for _, row in summary_df.iterrows():
    feat = row.name
    score = row["çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢"]
    judgment = row["åˆ¤å®š"]

    if "é«˜ç¢ºä¿¡" in judgment:
        color = "#1565C0"
    elif "ä½ç¢ºä¿¡" in judgment:
        color = "#64B5F6"
    else:
        color = "#E0E0E0"

    fig_score.add_trace(go.Bar(
        y=[feat], x=[score], orientation="h",
        marker_color=color, showlegend=False,
        text=f"{score:.3f} ({judgment})", textposition="outside",
        hovertemplate=(
            f"<b>{feat}</b><br>"
            f"|åŠ¹æœé‡|: {row['|åŠ¹æœé‡(std)|']:.3f} SD<br>"
            f"å› æœç¢ºä¿¡åº¦: {row['å› æœç¢ºä¿¡åº¦']:.2f}<br>"
            f"çµ±åˆã‚¹ã‚³ã‚¢: {score:.3f}<extra></extra>"
        ),
    ))

fig_score.update_layout(
    xaxis_title="çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢ (|åŠ¹æœé‡| Ã— å› æœç¢ºä¿¡åº¦)",
    yaxis=dict(autorange="reversed"),
    height=max(400, len(features) * 40),
    margin=dict(t=10, l=120, r=150),
)
st.plotly_chart(fig_score, use_container_width=True)

# ============================================================
# å†…è¨³: åŠ¹æœé‡ ã¨ å› æœç¢ºä¿¡åº¦ ã‚’ä¸¦ã¹ã¦è¡¨ç¤º
# ============================================================

col_effect, col_conf = st.columns(2)

with col_effect:
    st.markdown(f"**åŠ¹æœé‡ |Î²| (æ¨™æº–åŒ–, SD å˜ä½)**")
    fig_eff = go.Figure()
    for _, row in summary_df.iterrows():
        feat = row.name
        eff = row["åŠ¹æœé‡(std)"]
        src = row["åŠ¹æœé‡ã‚½ãƒ¼ã‚¹"]
        judgment = row["åˆ¤å®š"]
        if "é«˜ç¢ºä¿¡" in judgment:
            color = "#1565C0"
        elif "ä½ç¢ºä¿¡" in judgment:
            color = "#64B5F6"
        else:
            color = "#E0E0E0"

        if has_lingam and not np.isnan(row.get("ç›´æ¥åŠ¹æœ(std)", np.nan)):
            direct = row["ç›´æ¥åŠ¹æœ(std)"]
            indirect = row["é–“æ¥åŠ¹æœ(std)"]
            fig_eff.add_trace(go.Bar(
                y=[feat], x=[direct], orientation="h",
                marker_color=color, marker_opacity=1.0,
                name="ç›´æ¥", showlegend=(feat == summary_df.index[0]),
                legendgroup="direct",
            ))
            fig_eff.add_trace(go.Bar(
                y=[feat], x=[indirect], orientation="h",
                marker_color=color, marker_opacity=0.4,
                name="é–“æ¥", showlegend=(feat == summary_df.index[0]),
                legendgroup="indirect",
            ))
        else:
            fig_eff.add_trace(go.Bar(
                y=[feat], x=[eff], orientation="h",
                marker_color=color, showlegend=False,
                text=f"{eff:+.3f} ({src})", textposition="auto",
            ))
    fig_eff.update_layout(
        barmode="relative",
        xaxis_title="åŠ¹æœé‡ (SDå˜ä½)",
        yaxis=dict(autorange="reversed"),
        height=max(350, len(features) * 32),
        margin=dict(t=10, l=100),
        legend=dict(orientation="h", yanchor="bottom", y=1.02),
    )
    fig_eff.add_vline(x=0, line_color="gray", line_width=1)
    st.plotly_chart(fig_eff, use_container_width=True)

with col_conf:
    st.markdown(f"**å› æœç¢ºä¿¡åº¦ (å„æ‰‹æ³•ã®ç¢ºç‡)**")
    conf_cols_data = []
    method_names = []
    method_colors = []
    if has_lingam:
        conf_cols_data.append("LiNGAMç¢ºç‡")
        method_names.append("LiNGAM")
        method_colors.append("#283593")
    if has_pc:
        conf_cols_data.append("PCç¢ºç‡")
        method_names.append("PC")
        method_colors.append("#4527A0")
    if has_fci:
        conf_cols_data.append("FCIéš£æ¥")
        method_names.append("FCI")
        method_colors.append("#6A1B9A")
    if has_grasp:
        conf_cols_data.append("GRaSPç¢ºç‡")
        method_names.append("GRaSP")
        method_colors.append("#00838F")

    fig_conf = go.Figure()
    for col_name, m_name, m_color in zip(conf_cols_data, method_names, method_colors):
        fig_conf.add_trace(go.Bar(
            y=summary_df.index, x=summary_df[col_name].fillna(0),
            name=m_name, marker_color=m_color, orientation="h",
        ))

    # çµ±åˆç¢ºä¿¡åº¦ã‚’ç·šã§é‡ã­ã‚‹
    fig_conf.add_trace(go.Scatter(
        y=summary_df.index, x=summary_df["å› æœç¢ºä¿¡åº¦"],
        mode="markers+lines", name="çµ±åˆç¢ºä¿¡åº¦",
        marker=dict(color="#FF6F00", size=8, symbol="diamond"),
        line=dict(color="#FF6F00", width=2),
    ))

    fig_conf.update_layout(
        barmode="group",
        xaxis_title="ç¢ºç‡ / ç¢ºä¿¡åº¦",
        xaxis=dict(range=[0, 1.05]),
        yaxis=dict(autorange="reversed"),
        height=max(350, len(features) * 32),
        margin=dict(t=10, l=100),
        legend=dict(orientation="h", yanchor="bottom", y=1.02),
    )
    st.plotly_chart(fig_conf, use_container_width=True)

# ============================================================
# ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
# ============================================================

st.markdown("**å…¨å¤‰æ•°ã®è©³ç´°**")
display_cols = ["åˆ¤å®š", "çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢", "|åŠ¹æœé‡(std)|", "å› æœç¢ºä¿¡åº¦",
                "å› æœã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ•°"]
if has_lingam:
    display_cols += ["åŠ¹æœé‡(std)", "ç›´æ¥åŠ¹æœ(std)", "é–“æ¥åŠ¹æœ(std)", "LiNGAMç¢ºç‡"]
else:
    display_cols.append("åŠ¹æœé‡(std)")
if has_pc:
    display_cols.append("PCç¢ºç‡")
if has_fci:
    display_cols.append("FCIéš£æ¥")
if has_grasp:
    display_cols.append("GRaSPç¢ºç‡")
if gt:
    display_cols.append("çœŸã®ã‚«ãƒ†ã‚´ãƒª")

format_dict = {
    "çµ±åˆä»‹å…¥ã‚¹ã‚³ã‚¢": "{:.3f}",
    "|åŠ¹æœé‡(std)|": "{:.3f}",
    "å› æœç¢ºä¿¡åº¦": "{:.2f}",
    "åŠ¹æœé‡(std)": "{:+.3f}",
    "ç›´æ¥åŠ¹æœ(std)": "{:+.3f}",
    "é–“æ¥åŠ¹æœ(std)": "{:+.3f}",
    "LiNGAMç¢ºç‡": "{:.2f}",
    "PCç¢ºç‡": "{:.2f}",
    "GRaSPç¢ºç‡": "{:.2f}",
}

st.dataframe(
    summary_df[display_cols].style.format(
        format_dict, na_rep="â€”"
    ).apply(
        lambda row: [
            "background-color: #E3F2FD" if "é«˜ç¢ºä¿¡" in str(row.get("åˆ¤å®š", ""))
            else ""
            for _ in row
        ], axis=1
    ),
    use_container_width=True, height=min(600, 50 + len(features) * 35),
)

# ============================================================
# çµ±åˆå› æœã‚°ãƒ©ãƒ• + DoWhy çµæœ
# ============================================================

if "consensus_graph" in st.session_state and st.session_state["consensus_graph"] is not None:
    st.markdown("---")
    st.subheader("çµ±åˆå› æœã‚°ãƒ©ãƒ• (Consensus Graph)")
    st.caption(
        "2ã¤ä»¥ä¸Šã®æ‰‹æ³•ãŒæ¤œå‡ºã—ãŸã‚¨ãƒƒã‚¸ã®ã¿ã‚’æ¡ç”¨ã—ãŸçµ±åˆå› æœã‚°ãƒ©ãƒ•ã§ã™ã€‚"
        "ã“ã®ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ã¦ DoWhy ã«ã‚ˆã‚Šå› æœåŠ¹æœã‚’æ¨å®šã—ã¾ã™ã€‚"
    )

    with st.expander("ğŸ“Š çµ±åˆå› æœã‚°ãƒ©ãƒ•ã®è©³ç´°", expanded=False):
        consensus_graph = st.session_state["consensus_graph"]
        edge_support_df = st.session_state["edge_support_df"]

        # ã‚¨ãƒƒã‚¸ã‚µãƒãƒ¼ãƒˆæƒ…å ±
        st.markdown("**ã‚¨ãƒƒã‚¸ã‚µãƒãƒ¼ãƒˆæƒ…å ± (æ‰‹æ³•é–“ã®åˆæ„)**")
        st.dataframe(
            edge_support_df[[
                "From", "To", "support", "avg_probability", "directed", "methods"
            ]].rename(columns={
                "From": "èµ·ç‚¹", "To": "çµ‚ç‚¹", "support": "æ‰‹æ³•æ•°",
                "avg_probability": "å¹³å‡ç¢ºç‡", "directed": "æœ‰å‘", "methods": "æ¤œå‡ºæ‰‹æ³•"
            }),
            use_container_width=True,
        )

        # çµ±åˆã‚°ãƒ©ãƒ•ã®å¯è¦–åŒ–
        st.markdown("**çµ±åˆå› æœã‚°ãƒ©ãƒ• (2+ æ‰‹æ³•ãŒåˆæ„ã—ãŸã‚¨ãƒƒã‚¸ã®ã¿)**")
        if len(edge_support_df) > 0:
            fig_consensus, ax = plt.subplots(figsize=(12, 8))
            pos = nx.spring_layout(consensus_graph, seed=42, k=2)

            if gt:
                nc = [_color(n) if n != target else "#4CAF50" for n in consensus_graph.nodes()]
            else:
                nc = ["#4CAF50" if n == target else "#2196F3" for n in consensus_graph.nodes()]

            # ã‚¨ãƒƒã‚¸ã®è‰²ã‚’ support æ•°ã§å¤‰ãˆã‚‹
            edge_colors = []
            edge_widths = []
            for u, v, data in consensus_graph.edges(data=True):
                support = data.get("support", 1)
                edge_widths.append(1 + support * 0.5)
                if support >= 4:
                    edge_colors.append("#1565C0")  # æ¿ƒã„é’ (å¼·ã„åˆæ„)
                elif support >= 3:
                    edge_colors.append("#42A5F5")  # é’
                else:
                    edge_colors.append("#90CAF9")  # è–„ã„é’

            nx.draw(
                consensus_graph, pos, ax=ax, with_labels=True, node_color=nc,
                node_size=800, font_size=9, font_weight="bold",
                edge_color=edge_colors, width=edge_widths,
                arrows=True, arrowsize=15, connectionstyle="arc3,rad=0.1"
            )

            # ã‚µãƒãƒ¼ãƒˆæ•°ã‚’ã‚¨ãƒƒã‚¸ãƒ©ãƒ™ãƒ«ã«è¡¨ç¤º
            edge_labels = {}
            for u, v, data in consensus_graph.edges(data=True):
                if not data.get("undirected", False):
                    support = data.get("support", "?")
                    edge_labels[(u, v)] = f"({support})"

            nx.draw_networkx_edge_labels(
                consensus_graph, pos, edge_labels, font_size=7, ax=ax
            )
            ax.set_title("çµ±åˆå› æœã‚°ãƒ©ãƒ• (æ‹¬å¼§å†…: ã‚µãƒãƒ¼ãƒˆæ‰‹æ³•æ•°)")
            st.pyplot(fig_consensus)
            plt.close(fig_consensus)
        else:
            st.warning("åˆæ„ã•ã‚ŒãŸã‚¨ãƒƒã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (å…¨æ‰‹æ³•ã§ç•°ãªã‚‹çµæœ)ã€‚")

        # DoWhy æ¨å®šçµæœ
        if has_dowhy:
            st.markdown("**DoWhy å› æœåŠ¹æœæ¨å®šçµæœ**")
            dowhy_df_rows = []
            for feat, res in dowhy_results.items():
                dowhy_df_rows.append({
                    "å¤‰æ•°": feat,
                    "ATE (å¹³å‡å› æœåŠ¹æœ)": res.get("ate", np.nan),
                    "æ¨™æº–èª¤å·®": res.get("stderr", np.nan),
                    "è­˜åˆ¥å¯èƒ½": "Yes" if res.get("identified", False) else "No",
                    "ã‚¨ãƒ©ãƒ¼": res.get("error", ""),
                })
            dowhy_df = pd.DataFrame(dowhy_df_rows).set_index("å¤‰æ•°")
            dowhy_df = dowhy_df.sort_values("ATE (å¹³å‡å› æœåŠ¹æœ)", key=abs, ascending=False)

            st.dataframe(
                dowhy_df.style.format({
                    "ATE (å¹³å‡å› æœåŠ¹æœ)": "{:+.4f}",
                    "æ¨™æº–èª¤å·®": "{:.4f}",
                }, na_rep="â€”"),
                use_container_width=True,
            )

            st.caption(
                "**ATE (Average Treatment Effect)**: å¤‰æ•°ã‚’1å˜ä½å¢—åŠ ã•ã›ãŸæ™‚ã®ç›®çš„å¤‰æ•°ã¸ã®å¹³å‡å› æœåŠ¹æœã€‚"
                "Backdoor criterion ã«åŸºã¥ãã€çµ±åˆã‚°ãƒ©ãƒ•ã‹ã‚‰äº¤çµ¡å› å­ã‚’èª¿æ•´ã—ã¦æ¨å®šã€‚"
            )


# ============================================================
# ãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# ============================================================

st.markdown("---")
st.subheader("ğŸ“¥ åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

col1, col2 = st.columns(2)

with col1:
    # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    from analysis.report_generator import generate_html_report

    html_report = generate_html_report(
        st.session_state,
        target,
        features,
        summary_df if 'summary_df' in locals() else None
    )

    st.download_button(
        label="ğŸ“„ HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=html_report,
        file_name=f"causal_analysis_report_{target}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
        mime="text/html",
        use_container_width=True,
    )
    st.caption("ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã‘ã‚‹HTMLå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆ")

with col2:
    # CSVãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
    if 'summary_df' in locals() and summary_df is not None:
        csv = summary_df.to_csv(index=True, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“Š ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ« (CSV)",
            data=csv,
            file_name=f"intervention_summary_{target}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            use_container_width=True,
        )
        st.caption("Excelç­‰ã§é–‹ã‘ã‚‹CSVå½¢å¼")


# ============================================================
# å„æ‰‹æ³•ã®è©³ç´°çµæœ (Expander)
# ============================================================

st.markdown("---")
st.subheader("å„æ‰‹æ³•ã®è©³ç´°çµæœ")

# ---- LiNGAM ----
if has_lingam:
    with st.expander("LiNGAM", expanded=False):
        res = st.session_state["lingam_result"]

        st.markdown("**æ¨å®šå› æœé †åº**")
        st.write(" â†’ ".join(res["causal_order"]))

        st.markdown(f"**{target} ã¸ã®æ¨å®šå› æœåŠ¹æœ (æ¨™æº–åŒ–: ç›´æ¥ vs ç·ä»‹å…¥åŠ¹æœ)**")
        std_d = res["std_direct_effects"]
        std_t = res["std_total_effects"]

        effect_comp = pd.DataFrame({
            "ç›´æ¥åŠ¹æœ (std)": std_d,
            "ç·ä»‹å…¥åŠ¹æœ (std)": std_t,
        }).sort_values("ç·ä»‹å…¥åŠ¹æœ (std)", key=abs, ascending=True)

        fig_eff = go.Figure()
        fig_eff.add_trace(go.Bar(
            y=effect_comp.index, x=effect_comp["ç›´æ¥åŠ¹æœ (std)"],
            name="ç›´æ¥åŠ¹æœ", marker_color="#1565C0", orientation="h",
        ))
        fig_eff.add_trace(go.Bar(
            y=effect_comp.index, x=effect_comp["ç·ä»‹å…¥åŠ¹æœ (std)"],
            name="ç·ä»‹å…¥åŠ¹æœ (ç›´æ¥+é–“æ¥)", marker_color="#FF9800", orientation="h",
        ))
        fig_eff.update_layout(
            barmode="group",
            xaxis_title="æ¨™æº–åŒ–å› æœåŠ¹æœ (SDå˜ä½)",
            height=500, margin=dict(t=30),
        )
        fig_eff.add_vline(x=0, line_color="gray", line_width=1)
        st.plotly_chart(fig_eff, use_container_width=True)
        st.caption(
            "æ¨™æº–åŒ–æ¸ˆã¿: ã€ŒX ã‚’ 1SD å¤‰åŒ–ã•ã›ãŸæ™‚ã« Y ãŒä½• SD å¤‰åŒ–ã™ã‚‹ã‹ã€ã€‚"
            "å¤‰æ•°é–“ã®ã‚¹ã‚±ãƒ¼ãƒ«å·®ã‚’å¸åã—ã€ä»‹å…¥åŠ¹æœã®å¤§ãã•ã‚’ç›´æ¥æ¯”è¼ƒå¯èƒ½ã€‚"
        )

        st.markdown("**Bootstrap ã‚¨ãƒƒã‚¸ç¢ºç‡**")
        probs_df = res["bootstrap_probs"]
        fig_heat = px.imshow(
            probs_df, text_auto=".2f", color_continuous_scale="YlOrRd",
            zmin=0, zmax=1, aspect="auto",
        )
        fig_heat.update_layout(height=600, margin=dict(t=30))
        st.plotly_chart(fig_heat, use_container_width=True)

        st.markdown("**æ¨å®š DAG**")
        edges_df = res["significant_edges"]
        if len(edges_df) > 0:
            G = nx.DiGraph()
            G.add_nodes_from(res["columns"])
            for _, row in edges_df.iterrows():
                G.add_edge(row["From"], row["To"], weight=abs(row["coefficient"]))

            fig_dag, ax = plt.subplots(figsize=(12, 8))
            pos = nx.spring_layout(G, seed=42, k=2)
            if gt:
                nc = [_color(n) if n != target else "#4CAF50" for n in G.nodes()]
            else:
                nc = ["#4CAF50" if n == target else "#2196F3" for n in G.nodes()]
            nx.draw(G, pos, ax=ax, with_labels=True, node_color=nc,
                    node_size=800, font_size=9, font_weight="bold",
                    edge_color="#666", arrows=True, arrowsize=15,
                    connectionstyle="arc3,rad=0.1")
            edge_labels = {
                (r["From"], r["To"]): f"{r['coefficient']:.2f}"
                for _, r in edges_df.iterrows()
                if abs(r["coefficient"]) > 0.01
            }
            nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=7, ax=ax)
            ax.set_title("LiNGAM æ¨å®š DAG")
            st.pyplot(fig_dag)
            plt.close(fig_dag)
        else:
            st.warning("æœ‰æ„ãªã‚¨ãƒƒã‚¸ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.markdown("**æœ‰æ„ãªã‚¨ãƒƒã‚¸ä¸€è¦§**")
        st.dataframe(edges_df, use_container_width=True)

        if gt and gt.get("true_edges"):
            st.markdown("**çœŸã® DAG ã¨ã®æ¯”è¼ƒ**")
            true_edges = gt["true_edges"]
            true_skeleton = {frozenset(e) for e in true_edges}
            est_skeleton = {frozenset([r["From"], r["To"]])
                            for _, r in edges_df.iterrows()}
            correct = true_skeleton & est_skeleton
            prec = len(correct) / len(est_skeleton) if est_skeleton else 0
            rec = len(correct) / len(true_skeleton) if true_skeleton else 0
            f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0
            c1, c2, c3 = st.columns(3)
            c1.metric("Precision", f"{prec:.3f}")
            c2.metric("Recall", f"{rec:.3f}")
            c3.metric("F1", f"{f1:.3f}")

# ---- PC ----
if has_pc:
    with st.expander("PC ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", expanded=False):
        pc_res = st.session_state["pc_result"]

        st.markdown(f"**{target} ã®éš£æ¥ãƒãƒ¼ãƒ‰**")
        st.write(sorted(pc_res["adjacent_to_target"]))

        st.markdown("**æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒƒã‚¸**")
        st.dataframe(pc_res["edges_df"], use_container_width=True)

        st.markdown("**æ¨å®š CPDAG**")
        pc_edges = pc_res["edges_df"]
        if len(pc_edges) > 0:
            G_pc = nx.DiGraph()
            G_pc.add_nodes_from(pc_res["columns"])
            for _, row in pc_edges.iterrows():
                if row["type"] == "directed":
                    G_pc.add_edge(row["From"], row["To"])
                else:
                    G_pc.add_edge(row["From"], row["To"])
                    G_pc.add_edge(row["To"], row["From"])

            fig_pc, ax = plt.subplots(figsize=(12, 8))
            pos = nx.spring_layout(G_pc, seed=42, k=2)
            if gt:
                nc = [_color(n) if n != target else "#4CAF50" for n in G_pc.nodes()]
            else:
                nc = ["#4CAF50" if n == target else "#2196F3" for n in G_pc.nodes()]
            nx.draw(G_pc, pos, ax=ax, with_labels=True, node_color=nc,
                    node_size=800, font_size=9, font_weight="bold",
                    edge_color="#666", arrows=True, arrowsize=15,
                    connectionstyle="arc3,rad=0.1")
            ax.set_title("PC æ¨å®š CPDAG")
            st.pyplot(fig_pc)
            plt.close(fig_pc)

        st.markdown("**Bootstrap ã‚¨ãƒƒã‚¸ç¢ºç‡**")
        probs_df = pc_res["bootstrap_probs"]
        fig_heat = px.imshow(
            probs_df, text_auto=".2f", color_continuous_scale="YlOrRd",
            zmin=0, zmax=1, aspect="auto",
        )
        fig_heat.update_layout(height=600, margin=dict(t=30))
        st.plotly_chart(fig_heat, use_container_width=True)

        if gt and gt.get("true_edges"):
            st.markdown("**çœŸã® DAG ã¨ã®æ¯”è¼ƒ**")
            true_edges = gt["true_edges"]
            true_skeleton = {frozenset(e) for e in true_edges}
            pc_skeleton = {frozenset([r["From"], r["To"]])
                           for _, r in pc_edges.iterrows()}
            correct = true_skeleton & pc_skeleton
            prec = len(correct) / len(pc_skeleton) if pc_skeleton else 0
            rec = len(correct) / len(true_skeleton) if true_skeleton else 0
            f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0
            c1, c2, c3 = st.columns(3)
            c1.metric("Precision", f"{prec:.3f}")
            c2.metric("Recall", f"{rec:.3f}")
            c3.metric("F1", f"{f1:.3f}")

            true_direct = set(gt["direct_causes"])
            tp = true_direct & pc_res["adjacent_to_target"]
            fn = true_direct - pc_res["adjacent_to_target"]
            fp = pc_res["adjacent_to_target"] - true_direct
            st.markdown(f"**{target} ã®ç›´æ¥åŸå› ç‰¹å®š:**")
            st.write(f"- æ­£è§£ (TP): {sorted(tp)}")
            st.write(f"- è¦‹é€ƒã— (FN): {sorted(fn)}")
            st.write(f"- èª¤æ¤œå‡º (FP): {sorted(fp)}")

# ---- FCI ----
if has_fci:
    with st.expander("FCI ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", expanded=False):
        gfci_res = st.session_state["fci_result"]

        st.markdown(f"**{target} ã®éš£æ¥ãƒãƒ¼ãƒ‰**")
        st.write(sorted(gfci_res["adjacent_to_target"]))

        st.markdown("**æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒƒã‚¸**")
        from analysis.pc_fci_analysis import EDGE_TYPE_LABELS
        gfci_display = gfci_res["edges_df"].copy()
        if len(gfci_display) > 0:
            gfci_display["ç¨®åˆ¥"] = gfci_display["type"].map(
                lambda t: EDGE_TYPE_LABELS.get(t, t)
            )
        st.dataframe(gfci_display, use_container_width=True)

        if len(gfci_display) > 0:
            st.markdown("**ã‚¨ãƒƒã‚¸ç¨®åˆ¥ã®åˆ†å¸ƒ**")
            type_counts = gfci_display["ç¨®åˆ¥"].value_counts()
            fig_types = px.pie(values=type_counts.values,
                               names=type_counts.index,
                               title="FCI ã‚¨ãƒƒã‚¸ç¨®åˆ¥")
            fig_types.update_layout(height=400, margin=dict(t=40))
            st.plotly_chart(fig_types, use_container_width=True)

        st.markdown("**æ¨å®š PAG**")
        gfci_edges = gfci_res["edges_df"]
        if len(gfci_edges) > 0:
            G_gfci = nx.DiGraph()
            G_gfci.add_nodes_from(gfci_res["columns"])
            edge_styles = {}
            for _, row in gfci_edges.iterrows():
                G_gfci.add_edge(row["From"], row["To"])
                edge_styles[(row["From"], row["To"])] = row["type"]

            fig_gfci, ax = plt.subplots(figsize=(12, 8))
            pos = nx.spring_layout(G_gfci, seed=42, k=2)
            if gt:
                nc = [_color(n) if n != target else "#4CAF50" for n in G_gfci.nodes()]
            else:
                nc = ["#4CAF50" if n == target else "#2196F3" for n in G_gfci.nodes()]

            edge_colors = []
            for u, v in G_gfci.edges():
                etype = edge_styles.get((u, v), "directed")
                if etype == "bidirected":
                    edge_colors.append("#E91E63")
                elif etype in ("circle_arrow", "circle_circle"):
                    edge_colors.append("#9C27B0")
                else:
                    edge_colors.append("#666")

            nx.draw(G_gfci, pos, ax=ax, with_labels=True, node_color=nc,
                    node_size=800, font_size=9, font_weight="bold",
                    edge_color=edge_colors, arrows=True, arrowsize=15,
                    connectionstyle="arc3,rad=0.1")
            ax.set_title("FCI æ¨å®š PAG")
            st.pyplot(fig_gfci)
            plt.close(fig_gfci)

        if gt and gt.get("true_edges"):
            st.markdown("**çœŸã® DAG ã¨ã®æ¯”è¼ƒ**")
            true_direct = set(gt["direct_causes"])
            tp = true_direct & gfci_res["adjacent_to_target"]
            fn = true_direct - gfci_res["adjacent_to_target"]
            fp = gfci_res["adjacent_to_target"] - true_direct
            st.markdown(f"**{target} ã®ç›´æ¥åŸå› ç‰¹å®š:**")
            st.write(f"- æ­£è§£ (TP): {sorted(tp)}")
            st.write(f"- è¦‹é€ƒã— (FN): {sorted(fn)}")
            st.write(f"- èª¤æ¤œå‡º (FP): {sorted(fp)}")

# ---- GRaSP ----
if has_grasp:
    with st.expander("GRaSP (Greedy relaxation of Sparsest Permutation)", expanded=False):
        grasp_res = st.session_state["grasp_result"]

        st.markdown(f"**{target} ã®éš£æ¥ãƒãƒ¼ãƒ‰**")
        st.write(sorted(grasp_res["adjacent_to_target"]))

        st.markdown("**æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒƒã‚¸**")
        st.dataframe(grasp_res["edges_df"], use_container_width=True)

        st.markdown("**æ¨å®š CPDAG**")
        grasp_edges = grasp_res["edges_df"]
        if len(grasp_edges) > 0:
            G_grasp = nx.DiGraph()
            G_grasp.add_nodes_from(grasp_res["columns"])
            for _, row in grasp_edges.iterrows():
                if row["type"] == "directed":
                    G_grasp.add_edge(row["From"], row["To"])
                else:
                    G_grasp.add_edge(row["From"], row["To"])
                    G_grasp.add_edge(row["To"], row["From"])

            fig_grasp, ax = plt.subplots(figsize=(12, 8))
            pos = nx.spring_layout(G_grasp, seed=42, k=2)
            if gt:
                nc = [_color(n) if n != target else "#4CAF50" for n in G_grasp.nodes()]
            else:
                nc = ["#4CAF50" if n == target else "#2196F3" for n in G_grasp.nodes()]
            nx.draw(G_grasp, pos, ax=ax, with_labels=True, node_color=nc,
                    node_size=800, font_size=9, font_weight="bold",
                    edge_color="#666", arrows=True, arrowsize=15,
                    connectionstyle="arc3,rad=0.1")
            ax.set_title("GRaSP æ¨å®š CPDAG")
            st.pyplot(fig_grasp)
            plt.close(fig_grasp)

        st.markdown("**Bootstrap ã‚¨ãƒƒã‚¸ç¢ºç‡**")
        grasp_probs_df = grasp_res["bootstrap_probs"]
        fig_heat = px.imshow(
            grasp_probs_df, text_auto=".2f", color_continuous_scale="YlOrRd",
            zmin=0, zmax=1, aspect="auto",
        )
        fig_heat.update_layout(height=600, margin=dict(t=30))
        st.plotly_chart(fig_heat, use_container_width=True)

        if gt and gt.get("true_edges"):
            st.markdown("**çœŸã® DAG ã¨ã®æ¯”è¼ƒ**")
            true_edges = gt["true_edges"]
            true_skeleton = {frozenset(e) for e in true_edges}
            grasp_skeleton = {frozenset([r["From"], r["To"]])
                              for _, r in grasp_edges.iterrows()}
            correct = true_skeleton & grasp_skeleton
            prec = len(correct) / len(grasp_skeleton) if grasp_skeleton else 0
            rec = len(correct) / len(true_skeleton) if true_skeleton else 0
            f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0
            c1, c2, c3 = st.columns(3)
            c1.metric("Precision", f"{prec:.3f}")
            c2.metric("Recall", f"{rec:.3f}")
            c3.metric("F1", f"{f1:.3f}")

            true_direct = set(gt["direct_causes"])
            tp = true_direct & grasp_res["adjacent_to_target"]
            fn = true_direct - grasp_res["adjacent_to_target"]
            fp = grasp_res["adjacent_to_target"] - true_direct
            st.markdown(f"**{target} ã®ç›´æ¥åŸå› ç‰¹å®š:**")
            st.write(f"- æ­£è§£ (TP): {sorted(tp)}")
            st.write(f"- è¦‹é€ƒã— (FN): {sorted(fn)}")
            st.write(f"- èª¤æ¤œå‡º (FP): {sorted(fp)}")
